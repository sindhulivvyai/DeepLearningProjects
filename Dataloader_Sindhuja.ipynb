{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN7f7wZUYeU8EqaY8f5uVbN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsvOa_EaSYnk","executionInfo":{"status":"ok","timestamp":1753438998536,"user_tz":-330,"elapsed":49,"user":{"displayName":"Sindhuja S","userId":"17199322313890370252"}},"outputId":"ba923506-978f-4008-c0c5-c43023d052aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary: {'aimons': 2, 'apprendre': 3, \"aujourd'hui\": 4, 'beaucoup': 5, 'belle': 6, 'bibliothèque': 7, 'bien': 8, 'bleu': 9, 'bonjour': 10, \"c'est\": 11, 'ciel': 12, 'est': 13, 'fait': 14, 'français': 15, 'froid': 16, 'il': 17, \"j'aime\": 18, 'je': 19, 'journée': 20, 'la': 21, 'le': 22, 'merci': 23, 'nous': 24, 'où': 25, 'suis': 26, 'une': 27, 'vais': 28, 'voyager': 29, 'étudiant': 30, '<PAD>': 0, '<UNK>': 1}\n","\n","Batches:\n","\n","Batch 1:\n","tensor([[10,  0,  0],\n","        [23,  5,  0],\n","        [19, 26, 30],\n","        [19, 28,  8]])\n","\n","Batch 2:\n","tensor([[24,  2, 29,  0],\n","        [18,  3, 22, 15],\n","        [22, 12, 13,  9],\n","        [11, 27,  6, 20]])\n","\n","Batch 3:\n","tensor([[25, 13, 21,  7],\n","        [17, 14, 16,  4]])\n"]}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","# Step 1: Prepare French sentences\n","french_sentences = [\n","    \"je suis étudiant\",\n","    \"bonjour\",\n","    \"j'aime apprendre le français\",\n","    \"le ciel est bleu\",\n","    \"c'est une belle journée\",\n","    \"merci beaucoup\",\n","    \"je vais bien\",\n","    \"où est la bibliothèque\",\n","    \"il fait froid aujourd'hui\",\n","    \"nous aimons voyager\"\n","]\n","\n","# Step 2: Sort by length (number of words)\n","french_sentences.sort(key=lambda x: len(x.split()))\n","\n","# Step 3: Build vocabulary (map word → index)\n","def build_vocab(sentences):\n","    tokens = set(word for sentence in sentences for word in sentence.split())\n","    vocab = {word: idx+2 for idx, word in enumerate(sorted(tokens))}\n","    vocab[\"<PAD>\"] = 0\n","    vocab[\"<UNK>\"] = 1\n","    return vocab\n","\n","vocab = build_vocab(french_sentences)\n","\n","# Step 4: Dataset class\n","class FrenchDataset(Dataset):\n","    def __init__(self, sentences, vocab):\n","        self.sentences = sentences\n","        self.vocab = vocab\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","        tokens = self.sentences[idx].split()\n","        numericalized = [self.vocab.get(word, self.vocab[\"<UNK>\"]) for word in tokens]\n","        return torch.tensor(numericalized, dtype=torch.long)\n","\n","# Step 5: Custom collate function for padding\n","def collate_fn(batch):\n","    padded_batch = pad_sequence(batch, batch_first=True, padding_value=vocab[\"<PAD>\"])\n","    return padded_batch\n","\n","# Step 6: Create Dataset and DataLoader\n","dataset = FrenchDataset(french_sentences, vocab)\n","dataloader = DataLoader(dataset, batch_size=4, collate_fn=collate_fn)\n","\n","# Step 7: Print each batch\n","print(\"Vocabulary:\", vocab)\n","print(\"\\nBatches:\")\n","for i, batch in enumerate(dataloader):\n","    print(f\"\\nBatch {i+1}:\")\n","    print(batch)\n"]}]}